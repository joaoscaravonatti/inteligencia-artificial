{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"osr-intra-class-splitting.ipynb","provenance":[],"authorship_tag":"ABX9TyNrCLqKdBqMXGnMvxSE+j1F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jOn4xwYceFOh"},"source":["import os\n","import time as t\n","import random as rn\n","import numpy as np\n","import tensorflow as tf\n","import keras.backend as K\n","import matplotlib.pyplot as plt\n","from sklearn import svm, datasets\n","from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n","from keras import metrics, optimizers, regularizers\n","from keras.datasets import mnist, cifar10\n","from keras.models import Model, load_model\n","from keras.layers import Dense, Input, Reshape, Concatenate, Subtract, ZeroPadding2D\n","from keras.layers import LeakyReLU, BatchNormalization, Conv2D, Flatten, Dropout\n","from keras.layers import AveragePooling2D, Softmax\n","from keras.initializers import truncated_normal as tn\n","from tensorflow.keras.utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLkSiSD7gpMD"},"source":["def cal_openset_baccu(ground_truth=None, prediction=None, label_ref=None):\n","    \"\"\"Calculate balanced accuracy for open set recognition.\n","\n","    :param ground_truth: True labels.\n","    :param prediction: Predicted labels.\n","    :param label_ref: A list of class labels in ascending order.\n","    :return: Balanced accuracy.\n","    \"\"\"\n","\n","    # Abnormal samples have the label of zero which are considered negative\n","    matrix = confusion_matrix(ground_truth, prediction, labels=label_ref)\n","\n","    # Number of correctly predicted abnormal samples\n","    tn = matrix[0, 0]\n","\n","    # Number of correctly predicted normal samples\n","    tp = np.trace(matrix) - tn\n","\n","    num_pos = np.count_nonzero(ground_truth)\n","    num_neg = len(ground_truth) - num_pos\n","\n","    tnr = tn/num_neg\n","    tpr = tp/num_pos\n","    baccu = 0.5 * (tnr + tpr)\n","\n","    return baccu\n","\n","\n","def cal_closed_set_accu(ground_truth=None, prediction=None):\n","    \"\"\"Calculate conventional closed set accuracy.\n","\n","    :param ground_truth: True labels.\n","    :param prediction: Predicted labels.\n","    :return: Closed set accuracy.\n","    \"\"\"\n","\n","    closed_set_accuracy = accuracy_score(y_true=ground_truth, y_pred=prediction)\n","    print('Closed-set accuracy is %.4f' % closed_set_accuracy)\n","\n","    return closed_set_accuracy\n","\n","\n","def cal_modified_auc(ground_truth=None, prediction=None):\n","    \"\"\"Calculate modified AUC according to Neal et al.\n","\n","    :param ground_truth: True labels.\n","    :param prediction: Predicted logits values.\n","    :return: Modified AUC.\n","    \"\"\"\n","\n","    pred_abnormal = prediction[:, 0]\n","    pred_normal = np.max(prediction[:, 1:], axis=-1)\n","    pred_score = pred_abnormal - pred_normal\n","\n","    auc = roc_auc_score((ground_truth == 0)*1, pred_score)\n","    print('AUC is %.4f' % auc)\n","\n","    return auc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qBWUoYZGgvcH"},"source":["import scipy.io\n","\n","def set_seed(first_seed=2018):\n","    \"\"\"Set seed for reproducible results.\n","\n","    :param first_seed: Integer number as the global seed.\n","    \"\"\"\n","\n","    os.environ['PYTHONHASHSEED'] = '0'\n","    np.random.seed(first_seed)\n","    rn.seed(10)\n","\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    tf.compat.v1.set_random_seed(16)\n","\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    K.set_session(sess)\n","\n","\n","def _extract_data(data=None, label=None, target_lb=None):\n","    \"\"\"Extract dataset regarding given normal / abnormal labels-\n","\n","    :param data: A numpy tensor. First axis should be the number of samples.\n","    :param label: The corresponding labels for the data.\n","    :param target_lb: An integer value standing for the only one known class.\n","    :return: normal data, abnormal data, normal labels, abnormal labels\n","    \"\"\"\n","\n","    index = 0\n","    if isinstance(target_lb, int):\n","        index = index + (label == target_lb) * 1\n","    else:\n","        for lb in target_lb:\n","            index = index + (label == lb) * 1\n","\n","    normal_idx = np.where(index == 1)[0]\n","    abnormal_idx = np.where(index == 0)[0]\n","\n","    data_normal = data[normal_idx]\n","    data_abnormal = data[abnormal_idx]\n","\n","    label_normal = label[normal_idx]\n","    label_abnormal = label[abnormal_idx]\n","\n","    return data_normal, data_abnormal, label_normal, label_abnormal\n","\n","\n","def _reshape_data(data=None, data_shape=None, num_channels=None):\n","    \"\"\"Reshape image data into vectors / matrices / tensors.\n","\n","    :param data: A numpy tensor. First axis should be the number of samples.\n","    :param data_shape: Desired data shape. It should be a string.\n","    :param num_channels: Number of the channels of the given data.\n","    :return: Reshaped data.\n","    \"\"\"\n","\n","    num_samples = data.shape[0]\n","    data = data.reshape(num_samples, -1)\n","    num_features = data.shape[-1]\n","    height = int(np.sqrt(num_features / num_channels))\n","    width = num_features // (num_channels*height)\n","    if not isinstance(width, int):\n","        raise ValueError('\\nThe input images should be in square form...')\n","\n","    if data_shape == 'vector':\n","        pass\n","\n","    elif data_shape == 'matrix':\n","        if num_channels == 1:\n","            data = data.reshape(num_samples, height, width)\n","        elif num_channels == 3:\n","            data = data.reshape(num_samples, height, width, num_channels)\n","            # Transform RGB images into gray-scale images\n","            data = 0.2989 * data[:, :, :, 0] + 0.5870 * data[:, :, :, 1] + 0.1140 * data[:, :, :, 2]\n","            data = data.reshape(num_samples, height, width)\n","        else:\n","            raise ValueError('The input data should be either gray-scale images or color images...')\n","\n","    elif data_shape == 'tensor':\n","        data = data.reshape(num_samples, height, width, num_channels)\n","\n","    else:\n","        raise ValueError('\\nNo suitable data shape is found. Please enter a desired data shape...')\n","\n","    return data\n","\n","\n","def get_data(dataset=None, normal_class=None, data_format=None, preprocess='minmax'):\n","    \"\"\"Obtain the dataset in a desired form stored in a dictionary.\n","\n","    :param dataset: The name of desired dataset: mnist, fmnist or cifar10.\n","    :param normal_class: The class which is considered to be known during training.\n","    :param data_format: The desired data shape: vector, matrix or tensor.\n","    :param preprocess: The name of a preprocessing method: minmax or mean.\n","    :return: A dictionary containing training and testing samples.\n","    \"\"\"\n","\n","    if dataset == 'mnist':\n","        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n","        num_channel = 1\n","    elif dataset == 'cifar10':\n","        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","        num_channel = 3\n","    else:\n","        raise ValueError('\\nNo datasets are found. Please select one dataset...')\n","\n","    # Reshape data and its label into desired format\n","    y_train = np.reshape(y_train, newshape=(-1,))\n","    y_test = np.reshape(y_test, newshape=(-1,))\n","\n","    x_train = _reshape_data(data=x_train, data_shape=data_format, num_channels=num_channel)\n","    x_test = _reshape_data(data=x_test, data_shape=data_format, num_channels=num_channel)\n","\n","    # Data normalization\n","    x_train = (x_train / 255).astype('float32')\n","    x_test = (x_test / 255).astype('float32')\n","\n","    if preprocess == 'minmax':\n","        x_train = (x_train - np.min(x_train))/(np.max(x_train) - np.min(x_train))\n","        x_test = (x_test - np.min(x_test)) / (np.max(x_test) - np.min(x_test))\n","    elif preprocess == 'mean':\n","        x_train = x_train - np.mean(x_train)\n","        x_test = x_test - np.mean(x_test)\n","    else:\n","        raise ValueError('\\nPlease give a valid preprocessing method...')\n","\n","    if normal_class is None:\n","        data = {'x_train': x_train,\n","                'y_train': y_train,\n","                'x_test': x_test,\n","                'y_test': y_test}\n","    else:\n","        train_set = _extract_data(data=x_train, label=y_train, target_lb=normal_class)\n","        test_set = _extract_data(data=x_test, label=y_test, target_lb=normal_class)\n","\n","        data = {'x_train_normal': train_set[0], 'x_train_abnormal': train_set[1],\n","                'y_train_normal': train_set[2], 'y_train_abnormal': train_set[3],\n","                'x_test_normal': test_set[0], 'x_test_abnormal': test_set[1],\n","                'y_test_normal': test_set[2], 'y_test_abnormal': test_set[3]}\n","    return data\n","\n","\n","# ==================== Image Processing ====================\n","\n","\n","def assign_label(normal_class=None, original_label=None, include_zero=None):\n","    \"\"\"Assign labels to the selected known classes.\n","\n","    :param normal_class: A list of unique selected known classes labels.\n","    :param original_label: A list of selected known classes samples' labels-\n","    :param include_zero: Boolean variable. True for include zero as the starting label. Otherwise one.\n","    :return: Modified labels.\n","    \"\"\"\n","\n","    num_normal_cls = len(normal_class)\n","\n","    temp_lb = 0\n","    for idx in range(num_normal_cls):\n","        temp_lb = temp_lb + (original_label == normal_class[idx]) * idx\n","\n","    # New labels begin with 1\n","    if not include_zero:\n","        temp_lb = temp_lb + 1\n","    return temp_lb\n","\n","\n","def split_data(model_name=None, data=None, rho=None, split_method=None, ground_truth=None, normal_class=None):\n","    \"\"\"Split the dataset according to a given split method.\n","\n","    :param model_name: The name for the model used for splitting.\n","    :param data: Selected known classes training data.\n","    :param rho: Splitting ratio.\n","    :param split_method: The name of splitting method: cnn.\n","    :param ground_truth: Original label list for the selected training samples.\n","    :param normal_class: A list of selected known classes.\n","    :return: Indices of typical and atypical samples in the training dataset.\n","    \"\"\"\n","\n","    cnn_path = './trained_models/cnn_for_ds_%s.h5' % model_name\n","\n","    print('\\nSplitting data...')\n","\n","    if split_method == 'cnn':\n","        if os.path.isfile(cnn_path):\n","            model = load_model(filepath=cnn_path, compile=False)\n","        else:\n","            raise ValueError('No suitable CNN for data splitting...')\n","\n","        print('\\nCalculating categorical probability using trained CNN...')\n","        probability = model.predict(data, batch_size=128)\n","        pred = to_categorical(np.argmax(probability, axis=-1), num_classes=probability.shape[-1])\n","\n","        gt = assign_label(normal_class=normal_class, original_label=ground_truth, include_zero=True)\n","        gt = to_categorical(gt, num_classes=len(normal_class))\n","        sim_score = gt * pred * probability\n","\n","        sim_score = np.max(sim_score, axis=-1)\n","        sim_thr = np.percentile(sim_score, rho)\n","\n","        print('\\nThe sim_thr is %.4f' % sim_thr)\n","    else:\n","        raise ValueError('No suitable data splitting method...')\n","\n","    typical_index = np.where(sim_score > sim_thr)\n","    atypical_index = np.where(sim_score <= sim_thr)\n","\n","    return typical_index, atypical_index\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tA8laok1g_8P"},"source":["def build_cnn(img_height=None, num_channel=None, reg=None, latent_fea=None, num_normal_class=None, cnn_type=None):\n","    \"\"\"Build CNN or OSRNET.\n","\n","    :param img_height: Input image height (width should be equal to this).\n","    :param num_channel: Number of image channels.\n","    :param reg: Decay of regularization terms.\n","    :param latent_fea: Number of latent features.\n","    :param num_normal_class: Number of known classes.\n","    :param cnn_type: The name of the CNN used as a backbone: modified_vgg, alexnet, mlp, densenet, etc.\n","    :return: A list of models.\n","    \"\"\"\n","\n","    # ==================== Constants Definition ====================\n","    acti_func = 'linear'\n","    clf_acti = 'softmax'\n","\n","    acti_alpha = 0.2\n","    set_bias = False\n","\n","    weights_init = tn(mean=0, stddev=0.01)\n","\n","    bn_eps = 1e-3\n","    bn_m = 0.99\n","\n","    logits_layer = None\n","\n","    # ==================== General Input Layer ====================\n","    input_layer = Input(shape=(img_height, img_height, num_channel), name='input_layer')\n","\n","    if cnn_type == 'modified_vgg':\n","\n","        conv_1 = Conv2D(filters=32, kernel_size=(3, 3), activation=acti_func, name='conv_1',\n","                        padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                        kernel_initializer=weights_init)(input_layer)\n","        conv_11 = Conv2D(filters=32, kernel_size=(3, 3), activation=acti_func, name='conv_11',\n","                         padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                         kernel_initializer=weights_init)(conv_1)\n","        conv_1 = Concatenate()([conv_1, conv_11])  # 32x32x64\n","\n","        lrelu_1 = LeakyReLU(alpha=acti_alpha)(conv_1)\n","\n","        pool_1 = AveragePooling2D(pool_size=(2, 2), name='pool_1')(lrelu_1)  # 16x16 / 14x14\n","\n","        bn_1 = BatchNormalization(momentum=bn_m, epsilon=bn_eps, name='bn_1')(pool_1)\n","\n","        conv_2 = Conv2D(filters=64, kernel_size=(3, 3), activation=acti_func, name='conv_2',\n","                        padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                        kernel_initializer=weights_init)(bn_1)\n","        conv_22 = Conv2D(filters=64, kernel_size=(3, 3), activation=acti_func, name='conv_22',\n","                         padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                         kernel_initializer=weights_init)(conv_2)\n","        conv_2 = Concatenate()([conv_2, conv_22])  # 16x16x128\n","\n","        lrelu_2 = LeakyReLU(alpha=acti_alpha)(conv_2)\n","\n","        pool_2 = AveragePooling2D(pool_size=(2, 2), name='pool_2')(lrelu_2)  # 8x8 / 7x7\n","\n","        if img_height == 28:\n","            pool_2 = ZeroPadding2D(padding=(1, 1))(pool_2)  # zero-padding if mnist or fashion-mnist\n","\n","        bn_2 = BatchNormalization(momentum=bn_m, epsilon=bn_eps, name='bn_2')(pool_2)\n","\n","        conv_3 = Conv2D(filters=128, kernel_size=(3, 3), activation=acti_func, name='conv_3',\n","                        padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                        kernel_initializer=weights_init)(bn_2)\n","        conv_33 = Conv2D(filters=128, kernel_size=(3, 3), activation=acti_func, name='conv_33',\n","                         padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                         kernel_initializer=weights_init)(conv_3)\n","        conv_3 = Concatenate()([conv_3, conv_33])  # 8x8x256\n","\n","        lrelu_3 = LeakyReLU(alpha=acti_alpha)(conv_3)\n","\n","        pool_3 = AveragePooling2D(pool_size=(2, 2), name='pool_3')(lrelu_3)  # 4x4\n","\n","        bn_3 = BatchNormalization(momentum=bn_m, epsilon=bn_eps, name='bn_3')(pool_3)\n","\n","        conv_4 = Conv2D(filters=256, kernel_size=(3, 3), activation=acti_func, name='conv_4',\n","                        padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                        kernel_initializer=weights_init)(bn_3)\n","        conv_44 = Conv2D(filters=256, kernel_size=(3, 3), activation=acti_func, name='conv_44',\n","                         padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                         kernel_initializer=weights_init)(conv_4)\n","        conv_4 = Concatenate()([conv_4, conv_44])  # 4x4x512\n","\n","        lrelu_4 = LeakyReLU(alpha=acti_alpha)(conv_4)\n","\n","        pool_4 = AveragePooling2D(pool_size=(2, 2), name='pool_4')(lrelu_4)  # 2x2\n","\n","        bn_4 = BatchNormalization(momentum=bn_m, epsilon=bn_eps, name='bn_4')(pool_4)\n","\n","        conv_5 = Conv2D(filters=256, kernel_size=(1, 1), activation=acti_func, name='conv_5',\n","                        kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                        kernel_initializer=weights_init)(bn_4)  # 2x2\n","        conv_55 = Conv2D(filters=256, kernel_size=(1, 1), activation=acti_func, name='conv_55',\n","                         kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                         kernel_initializer=weights_init)(bn_4)\n","        conv_5 = Concatenate()([conv_5, conv_55])  # 2x2x512\n","\n","        lrelu_5 = LeakyReLU(alpha=acti_alpha)(conv_5)\n","\n","        bn_5 = BatchNormalization(name='bn_5')(lrelu_5)\n","\n","        flt_7 = Flatten()(bn_5)\n","\n","        dense_8 = Dense(units=256, activation=acti_func, name='dense_8',\n","                        kernel_regularizer=regularizers.l2(reg), use_bias=not set_bias,\n","                        kernel_initializer=weights_init)(flt_7)\n","\n","        lrelu_8 = LeakyReLU(alpha=acti_alpha)(dense_8)\n","\n","        drop_8 = Dropout(rate=0.5)(lrelu_8)\n","\n","        dense_9 = Dense(units=latent_fea, activation=acti_func, name='dense_9',\n","                        kernel_regularizer=regularizers.l2(reg), use_bias=not set_bias,\n","                        kernel_initializer=weights_init)(drop_8)\n","\n","        lrelu_9 = LeakyReLU(alpha=acti_alpha)(dense_9)\n","\n","        drop_9 = Dropout(rate=0.5)(lrelu_9)\n","\n","        dense_10 = Dense(units=num_normal_class, activation='linear', name='dense_10',\n","                         kernel_regularizer=regularizers.l2(reg), use_bias=not set_bias,\n","                         kernel_initializer=weights_init)(drop_9)\n","        sf_10 = Softmax()(dense_10)\n","\n","        top_layer = Reshape(target_shape=(-1,), name='top_layer')(sf_10)\n","        latent_layer = Reshape(target_shape=(-1,), name='latent_layer')(lrelu_9)\n","        logits_layer = Reshape(target_shape=(-1,), name='logits_layer')(dense_10)\n","\n","    elif cnn_type == 'logits_cnn':\n","\n","        conv_1 = Conv2D(filters=32, kernel_size=(7, 7), activation=acti_func, name='conv_1',\n","                        padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                        kernel_initializer=weights_init)(input_layer)\n","        conv_11 = Conv2D(filters=32, kernel_size=(7, 7), activation=acti_func, name='conv_11',\n","                         padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                         kernel_initializer=weights_init)(conv_1)\n","        conv_1 = Concatenate()([conv_1, conv_11])\n","\n","        lrelu_1 = LeakyReLU(alpha=acti_alpha)(conv_1)\n","\n","        pool_1 = AveragePooling2D(pool_size=(2, 2), name='pool_1')(lrelu_1)  # 16x16 / 14x14\n","\n","        bn_1 = BatchNormalization(name='bn_1')(pool_1)\n","\n","        conv_2 = Conv2D(filters=64, kernel_size=(3, 3), activation=acti_func, name='conv_2',\n","                        padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                        kernel_initializer=weights_init)(bn_1)\n","        conv_22 = Conv2D(filters=64, kernel_size=(3, 3), activation=acti_func, name='conv_22',\n","                         padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                         kernel_initializer=weights_init)(conv_2)\n","        conv_2 = Concatenate()([conv_2, conv_22])\n","\n","        lrelu_2 = LeakyReLU(alpha=acti_alpha)(conv_2)\n","\n","        pool_2 = AveragePooling2D(pool_size=(2, 2), name='pool_2')(lrelu_2)  # 8x8 / 7x7\n","\n","        if img_height == 28:\n","            pool_2 = ZeroPadding2D(padding=(1, 1))(pool_2)\n","\n","        bn_2 = BatchNormalization(name='bn_2')(pool_2)\n","\n","        conv_3 = Conv2D(filters=128, kernel_size=(3, 3), activation=acti_func, name='conv_3',\n","                        padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                        kernel_initializer=weights_init)(bn_2)\n","        conv_33 = Conv2D(filters=128, kernel_size=(3, 3), activation=acti_func, name='conv_33',\n","                         padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                         kernel_initializer=weights_init)(conv_3)\n","        conv_3 = Concatenate()([conv_3, conv_33])\n","\n","        lrelu_3 = LeakyReLU(alpha=acti_alpha)(conv_3)\n","\n","        pool_3 = AveragePooling2D(pool_size=(2, 2), name='pool_3')(lrelu_3)  # 4x4\n","\n","        bn_3 = BatchNormalization(name='bn_3')(pool_3)\n","\n","        conv_4 = Conv2D(filters=256, kernel_size=(3, 3), activation=acti_func, name='conv_4',\n","                        padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                        kernel_initializer=weights_init)(bn_3)\n","        conv_44 = Conv2D(filters=256, kernel_size=(3, 3), activation=acti_func, name='conv_44',\n","                         padding='same', kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                         kernel_initializer=weights_init)(conv_4)\n","        conv_4 = Concatenate()([conv_4, conv_44])\n","\n","        lrelu_4 = LeakyReLU(alpha=acti_alpha)(conv_4)\n","\n","        pool_4 = AveragePooling2D(pool_size=(2, 2), name='pool_4')(lrelu_4)  # 2x2\n","\n","        bn_4 = BatchNormalization(name='bn_4')(pool_4)\n","\n","        conv_5 = Conv2D(filters=256, kernel_size=(1, 1), activation=acti_func, name='conv_5',\n","                        kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                        kernel_initializer=weights_init)(bn_4)  # 2x2\n","        conv_55 = Conv2D(filters=256, kernel_size=(1, 1), activation=acti_func, name='conv_55',\n","                         kernel_regularizer=regularizers.l2(reg), use_bias=set_bias,\n","                         kernel_initializer=weights_init)(bn_4)\n","        conv_5 = Concatenate()([conv_5, conv_55])\n","\n","        lrelu_5 = LeakyReLU(alpha=acti_alpha)(conv_5)\n","\n","        bn_5 = BatchNormalization(name='bn_5')(lrelu_5)\n","\n","        flt_7 = Flatten()(bn_5)\n","\n","        dense_8 = Dense(units=256, activation=acti_func, name='dense_8',\n","                        kernel_regularizer=regularizers.l2(reg), use_bias=not set_bias,\n","                        kernel_initializer=weights_init)(flt_7)\n","\n","        lrelu_8 = LeakyReLU(alpha=acti_alpha)(dense_8)\n","\n","        drop_8 = Dropout(rate=0.5)(lrelu_8)\n","\n","        dense_9 = Dense(units=latent_fea, activation=acti_func, name='dense_9',\n","                        kernel_regularizer=regularizers.l2(reg), use_bias=not set_bias,\n","                        kernel_initializer=weights_init)(drop_8)\n","\n","        lrelu_9 = LeakyReLU(alpha=acti_alpha)(dense_9)\n","\n","        drop_9 = Dropout(rate=0.5)(lrelu_9)\n","\n","        dense_10 = Dense(units=num_normal_class, activation='linear', name='dense_10',\n","                         kernel_regularizer=regularizers.l2(reg), use_bias=not set_bias,\n","                         kernel_initializer=weights_init)(drop_9)\n","        clf_layer = Softmax(name='softmax')(dense_10)\n","\n","        top_layer = Reshape(target_shape=(-1,), name='top_layer')(clf_layer)\n","        latent_layer = Reshape(target_shape=(-1,), name='latent_layer')(dense_10)\n","        logits_layer = Reshape(target_shape=(-1,), name='latent_layer')(dense_10)\n","\n","    else:\n","        raise ValueError('No suitable CNN architecture...')\n","\n","    cnn = Model(inputs=input_layer, outputs=top_layer, name=cnn_type)\n","    cnn_latent = Model(inputs=input_layer, outputs=latent_layer, name=cnn_type + '_latent')\n","    cnn_logits = Model(inputs=input_layer, outputs=logits_layer, name=cnn_type + '_logits')\n","\n","    # ==================== Intra-Class Networks ====================\n","\n","    input_1 = Input(shape=(img_height, img_height, num_channel), name='input_1')\n","    input_2 = Input(shape=(img_height, img_height, num_channel), name='input_2')\n","\n","    lat_1 = cnn_latent(input_1)\n","    lat_2 = cnn_latent(input_2)\n","\n","    latent_dist = Subtract(name='latent_dist')([lat_1, lat_2])\n","\n","    dense_ly = Dense(units=1, activation='sigmoid', name='dense_ly',\n","                     kernel_regularizer=regularizers.l2(reg))(latent_dist)\n","\n","    ic_network = Model(inputs=[input_1, input_2], outputs=dense_ly)\n","\n","    # ==================== Joint layers ====================\n","    dense_11 = Dense(units=num_normal_class-1, activation='softmax', name='dense_joint',\n","                     kernel_regularizer=regularizers.l2(reg), use_bias=not set_bias,\n","                     kernel_initializer=weights_init)(latent_layer)\n","    joint_layer = Reshape(target_shape=(-1,), name='joint_layer')(dense_11)\n","\n","    joint_cnn = Model(inputs=input_layer, outputs=[top_layer, joint_layer])\n","\n","    # cnn.summary()\n","    # ic_network.summary()\n","\n","    return cnn, cnn_latent, joint_cnn, cnn_logits\n","\n","\n","def train_logits_cnn(data=None, label=None, normal_class=None, reg=None, epoch=None, batch_size=None, name=None):\n","    \"\"\"Train a normal CNN and save the layers from to bottom layer to logit output layer for further data splitting.\n","\n","    :param data: Training data in a 4D tensor.\n","    :param label: Corresponding original labels for the training data.\n","    :param normal_class: A list of selected known classes labels.\n","    :param reg: Decay for the regularization term.\n","    :param epoch: Trianing epochs.\n","    :param batch_size: The size of batch sizes.\n","    :param name: The name of the CNN for saving.\n","    :return: CNN models.\n","    \"\"\"\n","\n","    num_normal_class = len(normal_class)\n","    label = to_categorical(assign_label(normal_class=normal_class, original_label=label, include_zero=True))\n","    num_img, img_height, img_width, num_channel = data.shape[0], data.shape[1], data.shape[2], data.shape[-1]\n","\n","    model_set = build_cnn(img_height=img_height, num_channel=num_channel, reg=reg,\n","                          latent_fea=256, num_normal_class=num_normal_class, cnn_type='logits_cnn')\n","\n","    cnn = model_set[0]\n","    cnn_latent = model_set[1]\n","\n","    customized_optimizer = optimizers.RMSprop(lr=1e-4, decay=1e-9)\n","    cnn.compile(optimizer=customized_optimizer,\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","    cnn_latent.compile(optimizer=customized_optimizer,\n","                       loss='mse')\n","\n","    cnn.fit(x=data,\n","            y=label,\n","            batch_size=batch_size,\n","            epochs=epoch,\n","            verbose=2)\n","\n","    if name is not None:\n","        cnn_latent.save('./trained_models/cnn_for_ds_' + name + '.h5')\n","        return\n","    else:\n","        return cnn, cnn_latent\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vfSZR1M_hcNZ"},"source":["def train_joint_osrnet(data=None, name=None, rho=None, reg=None, latent_fea=None, num_epoch=None, batch_size=64,\n","                       split_method='cnn', normal_class=None, backbone='modified_vgg',\n","                       loss_weights=None, pretrain_ep=None):\n","\n","    # ==================== split training data ====================\n","    typical_index, atypical_index = split_data(model_name=name,\n","                                               data=data['x_train_normal'],\n","                                               rho=rho,\n","                                               split_method=split_method,\n","                                               ground_truth=data['y_train_normal'],\n","                                               normal_class=normal_class)\n","\n","    # ==================== assign labels to typical and atypical data====================\n","    typical_label = data['y_train_normal'][typical_index]\n","    atypical_label = data['y_train_normal'][atypical_index] * 0\n","\n","    typical_label = assign_label(normal_class=normal_class, original_label=typical_label, include_zero=False)\n","    print('\\nThere are %d typical normal samples and %d atypical normal samples...' % (len(typical_label),\n","                                                                                       len(atypical_label)))\n","\n","    # assign labels for closed-set regularization\n","    normal_label = assign_label(normal_class=normal_class, original_label=data['y_train_normal'], include_zero=True)\n","    normal_lb_ty = normal_label[typical_index]\n","    normal_lb_aty = normal_label[atypical_index]\n","    normal_label = np.concatenate([normal_lb_ty, normal_lb_aty])\n","\n","    # ==================== shuffle the training data ====================\n","    normal_x = np.vstack([data['x_train_normal'][typical_index], data['x_train_normal'][atypical_index]])\n","    normal_y = np.concatenate([typical_label, atypical_label])\n","\n","    training_idx = np.random.permutation(np.arange(0, len(normal_y)))\n","    normal_x = normal_x[training_idx]\n","    normal_y = normal_y[training_idx]\n","    normal_label = normal_label[training_idx]\n","\n","    # ==================== create and compile network ====================\n","    img_height, img_width = normal_x.shape[1], normal_x.shape[2]\n","    num_ch = normal_x.shape[-1]\n","    num_train = normal_x.shape[0]\n","    num_all_cls = 1 + len(normal_class)\n","    idx = np.arange(0, num_train)\n","\n","    model_set = build_cnn(img_height=img_height, num_channel=num_ch, reg=reg, latent_fea=latent_fea,\n","                          num_normal_class=num_all_cls, cnn_type=backbone)\n","\n","    customized_optimizer = optimizers.Adam(lr=3e-4, beta_1=0.5, clipvalue=1.0, decay=1e-10)\n","\n","    osrnet = model_set[0]\n","    osrnet_latent = model_set[1]\n","    osrnet_joint = model_set[2]\n","    osrnet_logits = model_set[3]\n","\n","    osrnet.compile(optimizer=customized_optimizer,\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","    osrnet_latent.compile(optimizer=customized_optimizer, loss='mse')\n","    osrnet_joint.compile(optimizer=customized_optimizer,\n","                         loss=['categorical_crossentropy', 'categorical_crossentropy'],\n","                         loss_weights=loss_weights)\n","    osrnet_logits.compile(optimizer=customized_optimizer, loss='mse')\n","\n","    # ==================== prepare test set ====================\n","    x_test = np.vstack([data['x_test_normal'], data['x_test_abnormal']])\n","    y_test_normal = assign_label(normal_class=normal_class, original_label=data['y_test_normal'], include_zero=False)\n","    y_test_gt = np.concatenate([y_test_normal, data['y_test_abnormal']*0])\n","\n","    # ==================== train the network====================\n","    best_baccu = 0\n","    best_auc = 0\n","    best_cs_accu = 0\n","\n","    res_baccu = []\n","    res_auc = []\n","    res_cs_accu = []\n","    res_train_accu = []\n","\n","    record_step = 5\n","\n","    # pre-train the network\n","    np.random.shuffle(idx)\n","    if pretrain_ep is not None:\n","        osrnet.fit(x=normal_x[idx],\n","                   y=to_categorical(normal_label+1)[idx],\n","                   batch_size=batch_size,\n","                   epochs=pretrain_ep,\n","                   verbose=2)\n","\n","    name = name + '_l1_%s_l2_%s' % (str(loss_weights[0]), str(loss_weights[1]))\n","    for i in range(num_epoch):\n","\n","        if (i + 1) % record_step == 0 or i == 0:\n","            print('\\nTraining for epoch %d' % (i+1))\n","            y_test_pred = np.argmax(osrnet.predict(x_test, batch_size=128), axis=-1)\n","            baccu = cal_openset_baccu(y_test_gt, y_test_pred, label_ref=np.arange(0, num_all_cls))\n","\n","            y_test_decision_function = osrnet_logits.predict(x_test, batch_size=128)\n","            auc = cal_modified_auc(y_test_gt, y_test_decision_function)\n","\n","            y_test_cs_pred = np.argmax(osrnet.predict(data['x_test_normal'], batch_size=128), axis=-1)\n","            cs_accu = cal_closed_set_accu(y_test_normal, y_test_cs_pred)\n","\n","            y_train_pred = np.argmax(osrnet.predict(normal_x[:500], batch_size=128), axis=-1)\n","            train_cs_accu = cal_closed_set_accu(normal_label[:500]+1, y_train_pred)\n","\n","            res_baccu.append(baccu)\n","            res_auc.append(auc)\n","            res_cs_accu.append(cs_accu)\n","            res_train_accu.append(train_cs_accu)\n","\n","            if baccu > best_baccu:\n","                best_baccu = baccu\n","                best_auc = auc\n","                best_cs_accu = cs_accu\n","                osrnet.save(filepath='./trained_models/osrnet_best_%s_rho_%d.h5' % (name, rho))\n","                osrnet_logits.save(filepath='./trained_models/osrnet_logits_best_%s_rho_%d.h5' % (name, rho))\n","\n","            print('\\nThe best baccu is %.4f' % best_baccu)\n","            print('The best auc is %.4f' % best_auc)\n","            print('The best cs accu is %.4f' % best_cs_accu)\n","\n","        osrnet_joint.fit(x=normal_x[idx],\n","                         y=[to_categorical(normal_y)[idx],\n","                            to_categorical(normal_label)[idx]],\n","                         batch_size=batch_size,\n","                         epochs=1,\n","                         verbose=0)\n","        np.random.shuffle(idx)\n","\n","    osrnet.save(filepath='./trained_models/osrnet_end_%s_rho_%d.h5' % (name, rho))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yIGoNoyJhe0i"},"source":["def run_osrnet(normal_class=None, dataset=None, rho=None):\n","    \"\"\"Run OSRNET for open set recognition\n","\n","    :param normal_class: A list of class labels that are considered as known classes during training.\n","    :param dataset: The name of a desired dataset: mnist, fmnist or cifar10.\n","    \"\"\"\n","\n","    set_seed()\n","\n","    # ========== constants ==========\n","    RHO = rho\n","    LOSS_WEIGHTS = [1., 1.]\n","    SPLIT_METHOD = 'cnn'\n","    TRAIN_EPOCH = 100\n","    BATCH_SIZE = 64\n","    PRE_TRAIN_EPOCH = 35\n","\n","    data = get_data(dataset,\n","                    normal_class=normal_class,\n","                    data_format='tensor')\n","\n","    num_cls = len(normal_class)\n","    name = dataset + '_'\n","    for idx in range(num_cls):\n","        name = name + str(normal_class[idx])\n","\n","    # Train a network for splitting the known classes\n","    train_logits_cnn(data=data['x_train_normal'],\n","                     label=data['y_train_normal'],\n","                     normal_class=normal_class,\n","                     reg=1e-3,\n","                     epoch=TRAIN_EPOCH,\n","                     batch_size=BATCH_SIZE,\n","                     name=name)\n","\n","    # Train an OSRNET\n","    train_joint_osrnet(data=data,\n","                       name=name,\n","                       rho=RHO,\n","                       reg=1e-3,\n","                       latent_fea=256,\n","                       num_epoch=TRAIN_EPOCH,\n","                       batch_size=BATCH_SIZE,\n","                       split_method=SPLIT_METHOD,\n","                       normal_class=normal_class,\n","                       backbone='modified_vgg',\n","                       loss_weights=LOSS_WEIGHTS,\n","                       pretrain_ep=PRE_TRAIN_EPOCH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cu4ntV-qhl9G","executionInfo":{"status":"ok","timestamp":1626398678135,"user_tz":180,"elapsed":2088151,"user":{"displayName":"Joao Victor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBeRlbW9hp9Xsay1_npEOeiisspB342V315OQMwQ=s64","userId":"03517608445459189517"}},"outputId":"b7961e30-9313-4c12-9a34-841b3a04c470"},"source":["run_osrnet(normal_class=[1, 3, 4, 6, 7, 9], dataset='mnist', rho=10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","576/576 - 12s - loss: 0.3553 - accuracy: 0.9500\n","Epoch 2/100\n","576/576 - 9s - loss: 0.1579 - accuracy: 0.9885\n","Epoch 3/100\n","576/576 - 9s - loss: 0.1184 - accuracy: 0.9903\n","Epoch 4/100\n","576/576 - 9s - loss: 0.0953 - accuracy: 0.9912\n","Epoch 5/100\n","576/576 - 9s - loss: 0.0797 - accuracy: 0.9926\n","Epoch 6/100\n","576/576 - 8s - loss: 0.0696 - accuracy: 0.9932\n","Epoch 7/100\n","576/576 - 8s - loss: 0.0624 - accuracy: 0.9937\n","Epoch 8/100\n","576/576 - 8s - loss: 0.0577 - accuracy: 0.9941\n","Epoch 9/100\n","576/576 - 8s - loss: 0.0547 - accuracy: 0.9944\n","Epoch 10/100\n","576/576 - 8s - loss: 0.0515 - accuracy: 0.9944\n","Epoch 11/100\n","576/576 - 9s - loss: 0.0490 - accuracy: 0.9947\n","Epoch 12/100\n","576/576 - 9s - loss: 0.0474 - accuracy: 0.9951\n","Epoch 13/100\n","576/576 - 9s - loss: 0.0468 - accuracy: 0.9950\n","Epoch 14/100\n","576/576 - 9s - loss: 0.0437 - accuracy: 0.9954\n","Epoch 15/100\n","576/576 - 9s - loss: 0.0433 - accuracy: 0.9952\n","Epoch 16/100\n","576/576 - 8s - loss: 0.0427 - accuracy: 0.9954\n","Epoch 17/100\n","576/576 - 8s - loss: 0.0405 - accuracy: 0.9960\n","Epoch 18/100\n","576/576 - 8s - loss: 0.0392 - accuracy: 0.9962\n","Epoch 19/100\n","576/576 - 9s - loss: 0.0373 - accuracy: 0.9961\n","Epoch 20/100\n","576/576 - 9s - loss: 0.0375 - accuracy: 0.9963\n","Epoch 21/100\n","576/576 - 8s - loss: 0.0359 - accuracy: 0.9963\n","Epoch 22/100\n","576/576 - 8s - loss: 0.0352 - accuracy: 0.9966\n","Epoch 23/100\n","576/576 - 8s - loss: 0.0349 - accuracy: 0.9963\n","Epoch 24/100\n","576/576 - 8s - loss: 0.0344 - accuracy: 0.9967\n","Epoch 25/100\n","576/576 - 8s - loss: 0.0336 - accuracy: 0.9964\n","Epoch 26/100\n","576/576 - 9s - loss: 0.0315 - accuracy: 0.9969\n","Epoch 27/100\n","576/576 - 9s - loss: 0.0304 - accuracy: 0.9974\n","Epoch 28/100\n","576/576 - 9s - loss: 0.0305 - accuracy: 0.9970\n","Epoch 29/100\n","576/576 - 8s - loss: 0.0308 - accuracy: 0.9973\n","Epoch 30/100\n","576/576 - 8s - loss: 0.0299 - accuracy: 0.9970\n","Epoch 31/100\n","576/576 - 8s - loss: 0.0297 - accuracy: 0.9973\n","Epoch 32/100\n","576/576 - 8s - loss: 0.0291 - accuracy: 0.9972\n","Epoch 33/100\n","576/576 - 8s - loss: 0.0288 - accuracy: 0.9972\n","Epoch 34/100\n","576/576 - 9s - loss: 0.0276 - accuracy: 0.9977\n","Epoch 35/100\n","576/576 - 9s - loss: 0.0286 - accuracy: 0.9969\n","Epoch 36/100\n","576/576 - 9s - loss: 0.0254 - accuracy: 0.9980\n","Epoch 37/100\n","576/576 - 8s - loss: 0.0256 - accuracy: 0.9979\n","Epoch 38/100\n","576/576 - 8s - loss: 0.0265 - accuracy: 0.9975\n","Epoch 39/100\n","576/576 - 8s - loss: 0.0257 - accuracy: 0.9977\n","Epoch 40/100\n","576/576 - 8s - loss: 0.0255 - accuracy: 0.9976\n","Epoch 41/100\n","576/576 - 8s - loss: 0.0246 - accuracy: 0.9979\n","Epoch 42/100\n","576/576 - 9s - loss: 0.0250 - accuracy: 0.9977\n","Epoch 43/100\n","576/576 - 9s - loss: 0.0255 - accuracy: 0.9977\n","Epoch 44/100\n","576/576 - 9s - loss: 0.0245 - accuracy: 0.9979\n","Epoch 45/100\n","576/576 - 8s - loss: 0.0241 - accuracy: 0.9978\n","Epoch 46/100\n","576/576 - 8s - loss: 0.0244 - accuracy: 0.9981\n","Epoch 47/100\n","576/576 - 8s - loss: 0.0241 - accuracy: 0.9979\n","Epoch 48/100\n","576/576 - 8s - loss: 0.0229 - accuracy: 0.9982\n","Epoch 49/100\n","576/576 - 9s - loss: 0.0239 - accuracy: 0.9979\n","Epoch 50/100\n","576/576 - 9s - loss: 0.0233 - accuracy: 0.9980\n","Epoch 51/100\n","576/576 - 9s - loss: 0.0224 - accuracy: 0.9983\n","Epoch 52/100\n","576/576 - 9s - loss: 0.0223 - accuracy: 0.9982\n","Epoch 53/100\n","576/576 - 8s - loss: 0.0211 - accuracy: 0.9985\n","Epoch 54/100\n","576/576 - 9s - loss: 0.0217 - accuracy: 0.9983\n","Epoch 55/100\n","576/576 - 9s - loss: 0.0222 - accuracy: 0.9982\n","Epoch 56/100\n","576/576 - 8s - loss: 0.0205 - accuracy: 0.9988\n","Epoch 57/100\n","576/576 - 8s - loss: 0.0211 - accuracy: 0.9983\n","Epoch 58/100\n","576/576 - 8s - loss: 0.0207 - accuracy: 0.9986\n","Epoch 59/100\n","576/576 - 8s - loss: 0.0203 - accuracy: 0.9985\n","Epoch 60/100\n","576/576 - 8s - loss: 0.0199 - accuracy: 0.9986\n","Epoch 61/100\n","576/576 - 8s - loss: 0.0211 - accuracy: 0.9980\n","Epoch 62/100\n","576/576 - 9s - loss: 0.0206 - accuracy: 0.9982\n","Epoch 63/100\n","576/576 - 9s - loss: 0.0188 - accuracy: 0.9988\n","Epoch 64/100\n","576/576 - 8s - loss: 0.0188 - accuracy: 0.9986\n","Epoch 65/100\n","576/576 - 8s - loss: 0.0192 - accuracy: 0.9985\n","Epoch 66/100\n","576/576 - 8s - loss: 0.0194 - accuracy: 0.9983\n","Epoch 67/100\n","576/576 - 8s - loss: 0.0187 - accuracy: 0.9986\n","Epoch 68/100\n","576/576 - 8s - loss: 0.0168 - accuracy: 0.9992\n","Epoch 69/100\n","576/576 - 9s - loss: 0.0176 - accuracy: 0.9987\n","Epoch 70/100\n","576/576 - 9s - loss: 0.0190 - accuracy: 0.9983\n","Epoch 71/100\n","576/576 - 9s - loss: 0.0189 - accuracy: 0.9986\n","Epoch 72/100\n","576/576 - 8s - loss: 0.0179 - accuracy: 0.9987\n","Epoch 73/100\n","576/576 - 8s - loss: 0.0178 - accuracy: 0.9988\n","Epoch 74/100\n","576/576 - 8s - loss: 0.0166 - accuracy: 0.9989\n","Epoch 75/100\n","576/576 - 8s - loss: 0.0164 - accuracy: 0.9989\n","Epoch 76/100\n","576/576 - 8s - loss: 0.0176 - accuracy: 0.9985\n","Epoch 77/100\n","576/576 - 9s - loss: 0.0168 - accuracy: 0.9989\n","Epoch 78/100\n","576/576 - 9s - loss: 0.0157 - accuracy: 0.9991\n","Epoch 79/100\n","576/576 - 9s - loss: 0.0172 - accuracy: 0.9988\n","Epoch 80/100\n","576/576 - 8s - loss: 0.0173 - accuracy: 0.9988\n","Epoch 81/100\n","576/576 - 8s - loss: 0.0178 - accuracy: 0.9984\n","Epoch 82/100\n","576/576 - 8s - loss: 0.0167 - accuracy: 0.9988\n","Epoch 83/100\n","576/576 - 8s - loss: 0.0169 - accuracy: 0.9988\n","Epoch 84/100\n","576/576 - 8s - loss: 0.0164 - accuracy: 0.9989\n","Epoch 85/100\n","576/576 - 9s - loss: 0.0164 - accuracy: 0.9985\n","Epoch 86/100\n","576/576 - 9s - loss: 0.0173 - accuracy: 0.9985\n","Epoch 87/100\n","576/576 - 9s - loss: 0.0160 - accuracy: 0.9989\n","Epoch 88/100\n","576/576 - 9s - loss: 0.0167 - accuracy: 0.9987\n","Epoch 89/100\n","576/576 - 9s - loss: 0.0165 - accuracy: 0.9988\n","Epoch 90/100\n","576/576 - 9s - loss: 0.0159 - accuracy: 0.9990\n","Epoch 91/100\n","576/576 - 9s - loss: 0.0158 - accuracy: 0.9988\n","Epoch 92/100\n","576/576 - 8s - loss: 0.0148 - accuracy: 0.9991\n","Epoch 93/100\n","576/576 - 8s - loss: 0.0151 - accuracy: 0.9990\n","Epoch 94/100\n","576/576 - 8s - loss: 0.0148 - accuracy: 0.9992\n","Epoch 95/100\n","576/576 - 8s - loss: 0.0157 - accuracy: 0.9990\n","Epoch 96/100\n","576/576 - 9s - loss: 0.0146 - accuracy: 0.9992\n","Epoch 97/100\n","576/576 - 9s - loss: 0.0152 - accuracy: 0.9989\n","Epoch 98/100\n","576/576 - 9s - loss: 0.0151 - accuracy: 0.9989\n","Epoch 99/100\n","576/576 - 8s - loss: 0.0154 - accuracy: 0.9988\n","Epoch 100/100\n","576/576 - 8s - loss: 0.0148 - accuracy: 0.9991\n","\n","Splitting data...\n","\n","Calculating categorical probability using trained CNN...\n","\n","The sim_thr is 7.6266\n","\n","There are 33162 typical normal samples and 3685 atypical normal samples...\n","Epoch 1/35\n","576/576 - 9s - loss: 0.2698 - accuracy: 0.9594\n","Epoch 2/35\n","576/576 - 7s - loss: 0.1270 - accuracy: 0.9853\n","Epoch 3/35\n","576/576 - 7s - loss: 0.1046 - accuracy: 0.9884\n","Epoch 4/35\n","576/576 - 7s - loss: 0.1039 - accuracy: 0.9881\n","Epoch 5/35\n","576/576 - 7s - loss: 0.0909 - accuracy: 0.9909\n","Epoch 6/35\n","576/576 - 7s - loss: 0.0890 - accuracy: 0.9904\n","Epoch 7/35\n","576/576 - 7s - loss: 0.0948 - accuracy: 0.9893\n","Epoch 8/35\n","576/576 - 7s - loss: 0.0895 - accuracy: 0.9903\n","Epoch 9/35\n","576/576 - 7s - loss: 0.0856 - accuracy: 0.9915\n","Epoch 10/35\n","576/576 - 7s - loss: 0.0940 - accuracy: 0.9899\n","Epoch 11/35\n","576/576 - 7s - loss: 0.0817 - accuracy: 0.9917\n","Epoch 12/35\n","576/576 - 7s - loss: 0.0818 - accuracy: 0.9916\n","Epoch 13/35\n","576/576 - 7s - loss: 0.0827 - accuracy: 0.9916\n","Epoch 14/35\n","576/576 - 7s - loss: 0.0792 - accuracy: 0.9926\n","Epoch 15/35\n","576/576 - 7s - loss: 0.0840 - accuracy: 0.9915\n","Epoch 16/35\n","576/576 - 7s - loss: 0.0790 - accuracy: 0.9929\n","Epoch 17/35\n","576/576 - 7s - loss: 0.0752 - accuracy: 0.9931\n","Epoch 18/35\n","576/576 - 7s - loss: 0.0848 - accuracy: 0.9916\n","Epoch 19/35\n","576/576 - 7s - loss: 0.0745 - accuracy: 0.9929\n","Epoch 20/35\n","576/576 - 7s - loss: 0.0755 - accuracy: 0.9923\n","Epoch 21/35\n","576/576 - 7s - loss: 0.0772 - accuracy: 0.9926\n","Epoch 22/35\n","576/576 - 7s - loss: 0.0752 - accuracy: 0.9937\n","Epoch 23/35\n","576/576 - 7s - loss: 0.0775 - accuracy: 0.9928\n","Epoch 24/35\n","576/576 - 7s - loss: 0.0728 - accuracy: 0.9931\n","Epoch 25/35\n","576/576 - 7s - loss: 0.0694 - accuracy: 0.9935\n","Epoch 26/35\n","576/576 - 7s - loss: 0.0655 - accuracy: 0.9940\n","Epoch 27/35\n","576/576 - 7s - loss: 0.0719 - accuracy: 0.9934\n","Epoch 28/35\n","576/576 - 7s - loss: 0.0761 - accuracy: 0.9928\n","Epoch 29/35\n","576/576 - 7s - loss: 0.0640 - accuracy: 0.9944\n","Epoch 30/35\n","576/576 - 7s - loss: 0.0608 - accuracy: 0.9949\n","Epoch 31/35\n","576/576 - 7s - loss: 0.0736 - accuracy: 0.9928\n","Epoch 32/35\n","576/576 - 7s - loss: 0.0597 - accuracy: 0.9951\n","Epoch 33/35\n","576/576 - 7s - loss: 0.0596 - accuracy: 0.9955\n","Epoch 34/35\n","576/576 - 7s - loss: 0.0587 - accuracy: 0.9950\n","Epoch 35/35\n","576/576 - 7s - loss: 0.0636 - accuracy: 0.9945\n","\n","Training for epoch 1\n","AUC is 0.9779\n","Closed-set accuracy is 0.9926\n","Closed-set accuracy is 0.9920\n","\n","The best baccu is 0.4963\n","The best auc is 0.9779\n","The best cs accu is 0.9926\n","\n","Training for epoch 5\n","AUC is 0.9289\n","Closed-set accuracy is 0.9005\n","Closed-set accuracy is 0.8940\n","\n","The best baccu is 0.8332\n","The best auc is 0.9289\n","The best cs accu is 0.9005\n","\n","Training for epoch 10\n","AUC is 0.8855\n","Closed-set accuracy is 0.8894\n","Closed-set accuracy is 0.8980\n","\n","The best baccu is 0.8332\n","The best auc is 0.9289\n","The best cs accu is 0.9005\n","\n","Training for epoch 15\n","AUC is 0.8481\n","Closed-set accuracy is 0.8902\n","Closed-set accuracy is 0.8960\n","\n","The best baccu is 0.8332\n","The best auc is 0.9289\n","The best cs accu is 0.9005\n","\n","Training for epoch 20\n","AUC is 0.9197\n","Closed-set accuracy is 0.9000\n","Closed-set accuracy is 0.9000\n","\n","The best baccu is 0.8332\n","The best auc is 0.9289\n","The best cs accu is 0.9005\n","\n","Training for epoch 25\n","AUC is 0.9312\n","Closed-set accuracy is 0.9121\n","Closed-set accuracy is 0.9200\n","\n","The best baccu is 0.8332\n","The best auc is 0.9289\n","The best cs accu is 0.9005\n","\n","Training for epoch 30\n","AUC is 0.8749\n","Closed-set accuracy is 0.9074\n","Closed-set accuracy is 0.9120\n","\n","The best baccu is 0.8332\n","The best auc is 0.9289\n","The best cs accu is 0.9005\n","\n","Training for epoch 35\n","AUC is 0.8885\n","Closed-set accuracy is 0.8796\n","Closed-set accuracy is 0.8920\n","\n","The best baccu is 0.8332\n","The best auc is 0.9289\n","The best cs accu is 0.9005\n","\n","Training for epoch 40\n","AUC is 0.8985\n","Closed-set accuracy is 0.9200\n","Closed-set accuracy is 0.9220\n","\n","The best baccu is 0.8332\n","The best auc is 0.9289\n","The best cs accu is 0.9005\n","\n","Training for epoch 45\n","AUC is 0.9205\n","Closed-set accuracy is 0.8651\n","Closed-set accuracy is 0.8880\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 50\n","AUC is 0.9216\n","Closed-set accuracy is 0.8884\n","Closed-set accuracy is 0.8980\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 55\n","AUC is 0.8796\n","Closed-set accuracy is 0.9200\n","Closed-set accuracy is 0.9200\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 60\n","AUC is 0.8897\n","Closed-set accuracy is 0.9044\n","Closed-set accuracy is 0.9120\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 65\n","AUC is 0.9020\n","Closed-set accuracy is 0.9271\n","Closed-set accuracy is 0.9240\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 70\n","AUC is 0.8714\n","Closed-set accuracy is 0.8435\n","Closed-set accuracy is 0.8760\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 75\n","AUC is 0.9111\n","Closed-set accuracy is 0.9374\n","Closed-set accuracy is 0.9280\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 80\n","AUC is 0.9208\n","Closed-set accuracy is 0.9258\n","Closed-set accuracy is 0.9160\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 85\n","AUC is 0.8799\n","Closed-set accuracy is 0.8342\n","Closed-set accuracy is 0.8680\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 90\n","AUC is 0.8823\n","Closed-set accuracy is 0.9167\n","Closed-set accuracy is 0.9180\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 95\n","AUC is 0.8924\n","Closed-set accuracy is 0.9007\n","Closed-set accuracy is 0.9040\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n","\n","Training for epoch 100\n","AUC is 0.9042\n","Closed-set accuracy is 0.8889\n","Closed-set accuracy is 0.8980\n","\n","The best baccu is 0.8427\n","The best auc is 0.9205\n","The best cs accu is 0.8651\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NrA2QECseRd3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626400554429,"user_tz":180,"elapsed":1876304,"user":{"displayName":"Joao Victor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBeRlbW9hp9Xsay1_npEOeiisspB342V315OQMwQ=s64","userId":"03517608445459189517"}},"outputId":"7c29ed56-9e97-49d8-848b-d9aca3c17d8a"},"source":["run_osrnet(normal_class=[1, 3, 4, 6, 7, 9], dataset='cifar10', rho=20)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","469/469 - 10s - loss: 1.3255 - accuracy: 0.5178\n","Epoch 2/100\n","469/469 - 7s - loss: 0.9608 - accuracy: 0.6911\n","Epoch 3/100\n","469/469 - 7s - loss: 0.8283 - accuracy: 0.7451\n","Epoch 4/100\n","469/469 - 7s - loss: 0.7272 - accuracy: 0.7833\n","Epoch 5/100\n","469/469 - 7s - loss: 0.6541 - accuracy: 0.8133\n","Epoch 6/100\n","469/469 - 7s - loss: 0.5936 - accuracy: 0.8329\n","Epoch 7/100\n","469/469 - 7s - loss: 0.5409 - accuracy: 0.8540\n","Epoch 8/100\n","469/469 - 7s - loss: 0.5017 - accuracy: 0.8714\n","Epoch 9/100\n","469/469 - 7s - loss: 0.4676 - accuracy: 0.8837\n","Epoch 10/100\n","469/469 - 7s - loss: 0.4353 - accuracy: 0.8951\n","Epoch 11/100\n","469/469 - 7s - loss: 0.4044 - accuracy: 0.9080\n","Epoch 12/100\n","469/469 - 7s - loss: 0.3796 - accuracy: 0.9164\n","Epoch 13/100\n","469/469 - 7s - loss: 0.3602 - accuracy: 0.9243\n","Epoch 14/100\n","469/469 - 7s - loss: 0.3395 - accuracy: 0.9359\n","Epoch 15/100\n","469/469 - 7s - loss: 0.3227 - accuracy: 0.9397\n","Epoch 16/100\n","469/469 - 7s - loss: 0.3112 - accuracy: 0.9461\n","Epoch 17/100\n","469/469 - 7s - loss: 0.3020 - accuracy: 0.9504\n","Epoch 18/100\n","469/469 - 7s - loss: 0.2887 - accuracy: 0.9564\n","Epoch 19/100\n","469/469 - 7s - loss: 0.2802 - accuracy: 0.9597\n","Epoch 20/100\n","469/469 - 7s - loss: 0.2747 - accuracy: 0.9600\n","Epoch 21/100\n","469/469 - 7s - loss: 0.2705 - accuracy: 0.9636\n","Epoch 22/100\n","469/469 - 7s - loss: 0.2645 - accuracy: 0.9653\n","Epoch 23/100\n","469/469 - 7s - loss: 0.2595 - accuracy: 0.9688\n","Epoch 24/100\n","469/469 - 7s - loss: 0.2526 - accuracy: 0.9714\n","Epoch 25/100\n","469/469 - 7s - loss: 0.2524 - accuracy: 0.9726\n","Epoch 26/100\n","469/469 - 7s - loss: 0.2466 - accuracy: 0.9735\n","Epoch 27/100\n","469/469 - 7s - loss: 0.2458 - accuracy: 0.9748\n","Epoch 28/100\n","469/469 - 7s - loss: 0.2409 - accuracy: 0.9761\n","Epoch 29/100\n","469/469 - 7s - loss: 0.2403 - accuracy: 0.9765\n","Epoch 30/100\n","469/469 - 7s - loss: 0.2410 - accuracy: 0.9761\n","Epoch 31/100\n","469/469 - 7s - loss: 0.2371 - accuracy: 0.9783\n","Epoch 32/100\n","469/469 - 7s - loss: 0.2332 - accuracy: 0.9793\n","Epoch 33/100\n","469/469 - 7s - loss: 0.2314 - accuracy: 0.9797\n","Epoch 34/100\n","469/469 - 7s - loss: 0.2272 - accuracy: 0.9806\n","Epoch 35/100\n","469/469 - 7s - loss: 0.2343 - accuracy: 0.9788\n","Epoch 36/100\n","469/469 - 7s - loss: 0.2275 - accuracy: 0.9804\n","Epoch 37/100\n","469/469 - 7s - loss: 0.2224 - accuracy: 0.9820\n","Epoch 38/100\n","469/469 - 7s - loss: 0.2232 - accuracy: 0.9816\n","Epoch 39/100\n","469/469 - 7s - loss: 0.2242 - accuracy: 0.9822\n","Epoch 40/100\n","469/469 - 7s - loss: 0.2199 - accuracy: 0.9817\n","Epoch 41/100\n","469/469 - 7s - loss: 0.2196 - accuracy: 0.9830\n","Epoch 42/100\n","469/469 - 7s - loss: 0.2181 - accuracy: 0.9833\n","Epoch 43/100\n","469/469 - 7s - loss: 0.2180 - accuracy: 0.9828\n","Epoch 44/100\n","469/469 - 7s - loss: 0.2156 - accuracy: 0.9834\n","Epoch 45/100\n","469/469 - 7s - loss: 0.2150 - accuracy: 0.9839\n","Epoch 46/100\n","469/469 - 7s - loss: 0.2113 - accuracy: 0.9844\n","Epoch 47/100\n","469/469 - 7s - loss: 0.2123 - accuracy: 0.9839\n","Epoch 48/100\n","469/469 - 7s - loss: 0.2116 - accuracy: 0.9838\n","Epoch 49/100\n","469/469 - 7s - loss: 0.2109 - accuracy: 0.9843\n","Epoch 50/100\n","469/469 - 7s - loss: 0.2103 - accuracy: 0.9836\n","Epoch 51/100\n","469/469 - 7s - loss: 0.2075 - accuracy: 0.9858\n","Epoch 52/100\n","469/469 - 7s - loss: 0.2094 - accuracy: 0.9850\n","Epoch 53/100\n","469/469 - 7s - loss: 0.2062 - accuracy: 0.9862\n","Epoch 54/100\n","469/469 - 7s - loss: 0.2061 - accuracy: 0.9861\n","Epoch 55/100\n","469/469 - 7s - loss: 0.2012 - accuracy: 0.9867\n","Epoch 56/100\n","469/469 - 7s - loss: 0.2057 - accuracy: 0.9846\n","Epoch 57/100\n","469/469 - 7s - loss: 0.1997 - accuracy: 0.9868\n","Epoch 58/100\n","469/469 - 7s - loss: 0.2008 - accuracy: 0.9862\n","Epoch 59/100\n","469/469 - 7s - loss: 0.1988 - accuracy: 0.9866\n","Epoch 60/100\n","469/469 - 7s - loss: 0.2008 - accuracy: 0.9860\n","Epoch 61/100\n","469/469 - 7s - loss: 0.1993 - accuracy: 0.9864\n","Epoch 62/100\n","469/469 - 7s - loss: 0.1944 - accuracy: 0.9885\n","Epoch 63/100\n","469/469 - 7s - loss: 0.1950 - accuracy: 0.9868\n","Epoch 64/100\n","469/469 - 7s - loss: 0.1966 - accuracy: 0.9869\n","Epoch 65/100\n","469/469 - 7s - loss: 0.1980 - accuracy: 0.9863\n","Epoch 66/100\n","469/469 - 7s - loss: 0.1928 - accuracy: 0.9875\n","Epoch 67/100\n","469/469 - 7s - loss: 0.1903 - accuracy: 0.9883\n","Epoch 68/100\n","469/469 - 7s - loss: 0.1937 - accuracy: 0.9873\n","Epoch 69/100\n","469/469 - 7s - loss: 0.1925 - accuracy: 0.9876\n","Epoch 70/100\n","469/469 - 7s - loss: 0.1894 - accuracy: 0.9881\n","Epoch 71/100\n","469/469 - 7s - loss: 0.1890 - accuracy: 0.9876\n","Epoch 72/100\n","469/469 - 7s - loss: 0.1901 - accuracy: 0.9875\n","Epoch 73/100\n","469/469 - 7s - loss: 0.1866 - accuracy: 0.9888\n","Epoch 74/100\n","469/469 - 7s - loss: 0.1886 - accuracy: 0.9874\n","Epoch 75/100\n","469/469 - 7s - loss: 0.1912 - accuracy: 0.9863\n","Epoch 76/100\n","469/469 - 7s - loss: 0.1861 - accuracy: 0.9882\n","Epoch 77/100\n","469/469 - 7s - loss: 0.1839 - accuracy: 0.9884\n","Epoch 78/100\n","469/469 - 7s - loss: 0.1860 - accuracy: 0.9883\n","Epoch 79/100\n","469/469 - 7s - loss: 0.1840 - accuracy: 0.9883\n","Epoch 80/100\n","469/469 - 7s - loss: 0.1823 - accuracy: 0.9887\n","Epoch 81/100\n","469/469 - 7s - loss: 0.1797 - accuracy: 0.9896\n","Epoch 82/100\n","469/469 - 7s - loss: 0.1804 - accuracy: 0.9893\n","Epoch 83/100\n","469/469 - 7s - loss: 0.1812 - accuracy: 0.9885\n","Epoch 84/100\n","469/469 - 7s - loss: 0.1798 - accuracy: 0.9886\n","Epoch 85/100\n","469/469 - 7s - loss: 0.1791 - accuracy: 0.9890\n","Epoch 86/100\n","469/469 - 7s - loss: 0.1827 - accuracy: 0.9883\n","Epoch 87/100\n","469/469 - 7s - loss: 0.1757 - accuracy: 0.9896\n","Epoch 88/100\n","469/469 - 7s - loss: 0.1806 - accuracy: 0.9885\n","Epoch 89/100\n","469/469 - 7s - loss: 0.1789 - accuracy: 0.9888\n","Epoch 90/100\n","469/469 - 7s - loss: 0.1752 - accuracy: 0.9891\n","Epoch 91/100\n","469/469 - 7s - loss: 0.1767 - accuracy: 0.9890\n","Epoch 92/100\n","469/469 - 7s - loss: 0.1757 - accuracy: 0.9895\n","Epoch 93/100\n","469/469 - 7s - loss: 0.1775 - accuracy: 0.9891\n","Epoch 94/100\n","469/469 - 7s - loss: 0.1742 - accuracy: 0.9897\n","Epoch 95/100\n","469/469 - 7s - loss: 0.1748 - accuracy: 0.9893\n","Epoch 96/100\n","469/469 - 7s - loss: 0.1718 - accuracy: 0.9906\n","Epoch 97/100\n","469/469 - 7s - loss: 0.1728 - accuracy: 0.9892\n","Epoch 98/100\n","469/469 - 7s - loss: 0.1723 - accuracy: 0.9895\n","Epoch 99/100\n","469/469 - 7s - loss: 0.1742 - accuracy: 0.9889\n","Epoch 100/100\n","469/469 - 7s - loss: 0.1728 - accuracy: 0.9895\n","\n","Splitting data...\n","\n","Calculating categorical probability using trained CNN...\n","\n","The sim_thr is 3.1189\n","\n","There are 24000 typical normal samples and 6000 atypical normal samples...\n","Epoch 1/35\n","469/469 - 8s - loss: 1.2771 - accuracy: 0.5369\n","Epoch 2/35\n","469/469 - 5s - loss: 0.9264 - accuracy: 0.6974\n","Epoch 3/35\n","469/469 - 5s - loss: 0.7883 - accuracy: 0.7557\n","Epoch 4/35\n","469/469 - 5s - loss: 0.7025 - accuracy: 0.7933\n","Epoch 5/35\n","469/469 - 5s - loss: 0.6510 - accuracy: 0.8187\n","Epoch 6/35\n","469/469 - 5s - loss: 0.6135 - accuracy: 0.8355\n","Epoch 7/35\n","469/469 - 5s - loss: 0.5773 - accuracy: 0.8502\n","Epoch 8/35\n","469/469 - 5s - loss: 0.5527 - accuracy: 0.8615\n","Epoch 9/35\n","469/469 - 5s - loss: 0.5366 - accuracy: 0.8716\n","Epoch 10/35\n","469/469 - 5s - loss: 0.5221 - accuracy: 0.8762\n","Epoch 11/35\n","469/469 - 5s - loss: 0.4971 - accuracy: 0.8888\n","Epoch 12/35\n","469/469 - 5s - loss: 0.4859 - accuracy: 0.8942\n","Epoch 13/35\n","469/469 - 5s - loss: 0.4652 - accuracy: 0.9019\n","Epoch 14/35\n","469/469 - 5s - loss: 0.4575 - accuracy: 0.9086\n","Epoch 15/35\n","469/469 - 5s - loss: 0.4401 - accuracy: 0.9160\n","Epoch 16/35\n","469/469 - 5s - loss: 0.4278 - accuracy: 0.9219\n","Epoch 17/35\n","469/469 - 5s - loss: 0.4289 - accuracy: 0.9225\n","Epoch 18/35\n","469/469 - 5s - loss: 0.4054 - accuracy: 0.9316\n","Epoch 19/35\n","469/469 - 5s - loss: 0.4000 - accuracy: 0.9354\n","Epoch 20/35\n","469/469 - 5s - loss: 0.3915 - accuracy: 0.9392\n","Epoch 21/35\n","469/469 - 5s - loss: 0.3879 - accuracy: 0.9384\n","Epoch 22/35\n","469/469 - 5s - loss: 0.3749 - accuracy: 0.9457\n","Epoch 23/35\n","469/469 - 5s - loss: 0.3710 - accuracy: 0.9474\n","Epoch 24/35\n","469/469 - 5s - loss: 0.3684 - accuracy: 0.9491\n","Epoch 25/35\n","469/469 - 5s - loss: 0.3628 - accuracy: 0.9511\n","Epoch 26/35\n","469/469 - 5s - loss: 0.3660 - accuracy: 0.9510\n","Epoch 27/35\n","469/469 - 5s - loss: 0.3569 - accuracy: 0.9543\n","Epoch 28/35\n","469/469 - 5s - loss: 0.3526 - accuracy: 0.9560\n","Epoch 29/35\n","469/469 - 5s - loss: 0.3473 - accuracy: 0.9587\n","Epoch 30/35\n","469/469 - 5s - loss: 0.3367 - accuracy: 0.9615\n","Epoch 31/35\n","469/469 - 5s - loss: 0.3444 - accuracy: 0.9608\n","Epoch 32/35\n","469/469 - 5s - loss: 0.3330 - accuracy: 0.9623\n","Epoch 33/35\n","469/469 - 5s - loss: 0.3375 - accuracy: 0.9614\n","Epoch 34/35\n","469/469 - 5s - loss: 0.3324 - accuracy: 0.9630\n","Epoch 35/35\n","469/469 - 5s - loss: 0.3351 - accuracy: 0.9626\n","\n","Training for epoch 1\n","AUC is 0.7741\n","Closed-set accuracy is 0.8585\n","Closed-set accuracy is 0.9660\n","\n","The best baccu is 0.4293\n","The best auc is 0.7741\n","The best cs accu is 0.8585\n","\n","Training for epoch 5\n","AUC is 0.7412\n","Closed-set accuracy is 0.7480\n","Closed-set accuracy is 0.8020\n","\n","The best baccu is 0.5600\n","The best auc is 0.7412\n","The best cs accu is 0.7480\n","\n","Training for epoch 10\n","AUC is 0.7466\n","Closed-set accuracy is 0.7092\n","Closed-set accuracy is 0.7860\n","\n","The best baccu is 0.6090\n","The best auc is 0.7466\n","The best cs accu is 0.7092\n","\n","Training for epoch 15\n","AUC is 0.7197\n","Closed-set accuracy is 0.7348\n","Closed-set accuracy is 0.8220\n","\n","The best baccu is 0.6090\n","The best auc is 0.7466\n","The best cs accu is 0.7092\n","\n","Training for epoch 20\n","AUC is 0.7150\n","Closed-set accuracy is 0.7225\n","Closed-set accuracy is 0.8080\n","\n","The best baccu is 0.6090\n","The best auc is 0.7466\n","The best cs accu is 0.7092\n","\n","Training for epoch 25\n","AUC is 0.7387\n","Closed-set accuracy is 0.7175\n","Closed-set accuracy is 0.8060\n","\n","The best baccu is 0.6090\n","The best auc is 0.7466\n","The best cs accu is 0.7092\n","\n","Training for epoch 30\n","AUC is 0.7693\n","Closed-set accuracy is 0.6980\n","Closed-set accuracy is 0.7920\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 35\n","AUC is 0.7148\n","Closed-set accuracy is 0.6973\n","Closed-set accuracy is 0.7940\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 40\n","AUC is 0.7292\n","Closed-set accuracy is 0.7212\n","Closed-set accuracy is 0.8160\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 45\n","AUC is 0.7277\n","Closed-set accuracy is 0.7210\n","Closed-set accuracy is 0.8040\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 50\n","AUC is 0.7426\n","Closed-set accuracy is 0.7023\n","Closed-set accuracy is 0.7920\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 55\n","AUC is 0.7408\n","Closed-set accuracy is 0.7562\n","Closed-set accuracy is 0.8180\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 60\n","AUC is 0.7219\n","Closed-set accuracy is 0.6563\n","Closed-set accuracy is 0.7740\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 65\n","AUC is 0.7114\n","Closed-set accuracy is 0.6603\n","Closed-set accuracy is 0.7760\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 70\n","AUC is 0.7303\n","Closed-set accuracy is 0.6960\n","Closed-set accuracy is 0.7900\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 75\n","AUC is 0.7359\n","Closed-set accuracy is 0.7510\n","Closed-set accuracy is 0.8120\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 80\n","AUC is 0.7250\n","Closed-set accuracy is 0.6938\n","Closed-set accuracy is 0.7640\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 85\n","AUC is 0.7301\n","Closed-set accuracy is 0.7447\n","Closed-set accuracy is 0.8060\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 90\n","AUC is 0.7296\n","Closed-set accuracy is 0.7073\n","Closed-set accuracy is 0.7920\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 95\n","AUC is 0.7403\n","Closed-set accuracy is 0.7375\n","Closed-set accuracy is 0.7940\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n","\n","Training for epoch 100\n","AUC is 0.7340\n","Closed-set accuracy is 0.7368\n","Closed-set accuracy is 0.8100\n","\n","The best baccu is 0.6331\n","The best auc is 0.7693\n","The best cs accu is 0.6980\n"],"name":"stdout"}]}]}